{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path, path_ihsg, \n",
    "              save_file = True,\n",
    "              return_file = True,\n",
    "              set_index = None):\n",
    "\n",
    "\n",
    "    emiten = pd.read_csv(path, index_col = set_index)\n",
    "    ihsg = pd.read_csv(path_ihsg, index_col = set_index)\n",
    "    merged = pd.merge(emiten, ihsg, how='left', on='Date')\n",
    "    merged['Close+1'] = merged['Close_x'].shift(-1)\n",
    "\n",
    "    if save_file:\n",
    "        joblib.dump(merged, \"output/merged.pkl\")\n",
    "    \n",
    "    if return_file:\n",
    "        return merged\n",
    "\n",
    "\n",
    "\n",
    "def split_input_output(dataset,\n",
    "                       target_column,\n",
    "                       save_file = True,\n",
    "                       return_file = True):\n",
    "    \n",
    "    output_df = dataset[target_column]\n",
    "    input_df = dataset.drop([target_column],\n",
    "                            axis = 1)\n",
    "    \n",
    "    if save_file:\n",
    "        joblib.dump(output_df, \"output/output_df.pkl\")\n",
    "        joblib.dump(input_df, \"output/input_df.pkl\")\n",
    "    \n",
    "    if return_file:\n",
    "        return output_df, input_df\n",
    "\n",
    "def x_split(input_df, return_file=True, save_file=True):\n",
    "    X_train = input_df[:int(input_df.shape[0]*0.6)]\n",
    "    test_val = input_df[int(input_df.shape[0]*0.6):]\n",
    "    X_valid = test_val[:int(test_val.shape[0]*0.5)]\n",
    "    X_test = test_val[int(test_val.shape[0]*0.5):]\n",
    "\n",
    "    if save_file:\n",
    "        joblib.dump(X_train, \"output/X_train.pkl\")\n",
    "        joblib.dump(X_valid, \"output/X_valid.pkl\")\n",
    "        joblib.dump(X_test, \"output/X_test.pkl\")\n",
    "\n",
    "    if return_file:\n",
    "        return X_train, X_valid, X_test\n",
    "        \n",
    "def y_split(output_df, return_file=True, save_file=True):\n",
    "    y_train = output_df[:int(output_df.shape[0]*0.6)]\n",
    "    y_test_val = output_df[int(output_df.shape[0]*0.6):]\n",
    "    y_valid = y_test_val[:int(y_test_val.shape[0]*0.5)]\n",
    "    y_test = y_test_val[int(y_test_val.shape[0]*0.5):]\n",
    "    \n",
    "    if save_file:\n",
    "        joblib.dump(y_train, \"output/y_train.pkl\")\n",
    "        joblib.dump(y_valid, \"output/y_valid.pkl\")\n",
    "        joblib.dump(y_test, \"output/y_test.pkl\")\n",
    "\n",
    "    if return_file:\n",
    "        return y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/AMRT.csv\"\n",
    "DATA_PATH_IHSG = \"data/ihsg.csv\"\n",
    "TARGET_COLUMN = \"Close+1\"\n",
    "INDEX_COLUMN = \"Date\"\n",
    "\n",
    "data_house = read_data(DATA_PATH, DATA_PATH_IHSG,\n",
    "                       set_index = INDEX_COLUMN)\n",
    "output_df, input_df = split_input_output(\n",
    "                            data_house,\n",
    "                            TARGET_COLUMN)\n",
    "\n",
    "X_train, X_valid, X_test = x_split(input_df)\n",
    "y_train, y_valid, y_test = y_split(output_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_emiten(proceed):\n",
    "    proceed = proceed.drop(['Open_x', 'Open_y', 'High_x', 'High_y', 'Low_x', 'Low_y', 'Adj Close_x', 'Adj Close_y'], axis = 1)\n",
    "    proceed.rename(columns = {'Close_x':'Close', 'Volume_x':'Volume', 'Close_y':'Close_ihsg', 'Volume_y':'Volume_ihsg'}, inplace = True)\n",
    "    proceed[\"Volume\"].replace(to_replace=0, method='bfill')\n",
    "    proceed[\"Volume_ihsg\"].replace(to_replace=0, method='bfill')\n",
    "    proceed.replace(to_replace=0, method='bfill')\n",
    "    return proceed\n",
    "\n",
    "def process_y(y_data):\n",
    "    y_data.replace(to_replace=0, method='bfill')\n",
    "    return y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_data(save_file=True, return_file=True):\n",
    "    X_train = process_emiten(joblib.load(\"output/X_train.pkl\"))\n",
    "    X_valid = process_emiten(joblib.load(\"output/X_valid.pkl\"))\n",
    "    X_test = process_emiten(joblib.load(\"output/X_test.pkl\"))\n",
    "    y_train = process_y(joblib.load(\"output/y_train.pkl\"))\n",
    "    y_valid = process_y(joblib.load(\"output/y_valid.pkl\"))\n",
    "    y_test = process_y(joblib.load(\"output/y_test.pkl\"))\n",
    "    \n",
    "    if save_file:\n",
    "        joblib.dump(X_train, \"output/X_train_proceed.pkl\")\n",
    "        joblib.dump(X_valid, \"output/X_valid_proceed.pkl\")\n",
    "        joblib.dump(X_test, \"output/X_test_proceed.pkl\")\n",
    "        joblib.dump(y_train, \"output/y_train_final.pkl\")\n",
    "        joblib.dump(y_valid, \"output/y_valid_final.pkl\")\n",
    "        joblib.dump(y_test, \"output/y_test_final.pkl\")\n",
    "    if return_file:\n",
    "        X_train, X_valid, X_test, y_train, y_valid, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sma(xdata, save_file=True, return_file=True):\n",
    "    periode = [5,20,60,120]\n",
    "    alpha = [0.1, 0.3]\n",
    "    for i in periode:\n",
    "        for k in alpha:\n",
    "            xdata[\"SMA_\", i] = xdata.Close.rolling(i, min_periods=1).mean()\n",
    "            xdata[\"dis_sma\", i] = xdata[\"Close\"] - xdata[\"SMA_\", i]\n",
    "            xdata[\"em_\", k] = xdata.Close.ewm(alpha=k, adjust=False).mean()\n",
    "    xdata.rename(columns = {('SMA_', 5):'SMA_5',\n",
    "                        ('SMA_', 20):'SMA_20',\n",
    "                        ('SMA_', 60): 'SMA_60', \n",
    "                        ('SMA_', 120): 'SMA_120',\n",
    "                        ('em_', 0.1): 'em_0.1',\n",
    "                        ('em_', 0.3): 'em_0.3',\n",
    "                        ('dis_sma', 5): 'dis_sam_5',\n",
    "                        ('dis_sma', 20): 'dis_sam_20',\n",
    "                        ('dis_sma', 60): 'dis_sam_60',\n",
    "                        ('dis_sma', 120): 'dis_sam_120'}, inplace = True)\n",
    "    return xdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_sma(save_file=True, return_file=True):\n",
    "    X_train = make_sma(joblib.load(\"output/X_train_proceed.pkl\"))\n",
    "    X_valid = make_sma(joblib.load(\"output/X_valid_proceed.pkl\"))\n",
    "    X_test = make_sma(joblib.load(\"output/X_test_proceed.pkl\"))\n",
    "    \n",
    "    if save_file:\n",
    "        joblib.dump(X_train, \"output/X_train_final.pkl\")\n",
    "        joblib.dump(X_valid, \"output/X_valid_final.pkl\")\n",
    "        joblib.dump(X_test, \"output/X_test_final.pkl\")\n",
    "    if return_file:\n",
    "        X_train, X_valid, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import random\n",
    "import yaml\n",
    "import time\n",
    "\n",
    "ts_cv = TimeSeriesSplit(\n",
    "    n_splits=5,\n",
    "    max_train_size=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"params.yaml\", \"r\")\n",
    "params = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(params):\n",
    "    x_train = joblib.load(params['DUMP_TRAIN'])\n",
    "    y_train = joblib.load(params['Y_PATH_TRAIN'])\n",
    "    x_valid = joblib.load(params['DUMP_VALID'])\n",
    "    y_valid = joblib.load(params['Y_PATH_VALID'])\n",
    "\n",
    "    return x_train, y_train, x_valid, y_valid\n",
    "\n",
    "def model_ridge():\n",
    "    param_dist = {'alpha': [0.1, 0.25, 0.5, 0.75]}\n",
    "    base_model = Ridge(random_state=42)\n",
    "    return param_dist, base_model\n",
    "\n",
    "def model_lasso():\n",
    "    param_dist = {'alpha': np.random.uniform(0.01,3,1000)}\n",
    "    base_model = Lasso(random_state=42, selection='random')\n",
    "    return param_dist, base_model\n",
    "\n",
    "\n",
    "def model_rf():\n",
    "    param_dist = {\"n_estimators\": [100, 250, 500, 1000]}\n",
    "    base_model = RandomForestRegressor(random_state=0, n_jobs=-1)\n",
    "    return param_dist, base_model\n",
    "\n",
    "\n",
    "def model_svr():\n",
    "    param_dist = {'C': [0.25, 0.5, 1, 1.25]}\n",
    "    base_model = LinearSVR(dual=False, max_iter=10000)\n",
    "    return param_dist, base_model\n",
    "\n",
    "def random_search_cv(model, param, scoring, n_iter, x, y, verbosity=0):\n",
    "    random_fit = RandomizedSearchCV(estimator=model,\n",
    "                                    param_distributions=param,\n",
    "                                    scoring=scoring,\n",
    "                                    n_iter=n_iter,\n",
    "                                    cv=ts_cv,\n",
    "                                    random_state=0,\n",
    "                                    verbose=verbosity)\n",
    "    random_fit.fit(x, y)\n",
    "    return random_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(true, predicted):\n",
    "    mae = metrics.mean_absolute_error(true, predicted)\n",
    "    mse = metrics.mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n",
    "    r2_square = metrics.r2_score(true, predicted)\n",
    "    return mae, mse, rmse, r2_square\n",
    "\n",
    "\n",
    "def fit(x_train, y_train, model, model_param, general_params):\n",
    "    \"\"\"\n",
    "    Fit model\n",
    "\n",
    "    Args:\n",
    "        - model(callable): Sklearn / imblearn model\n",
    "        - model_param(dict): sklearn's RandomizedSearchCV param_distribution\n",
    "        - general_params(dict): general parameters for the function\n",
    "            - target(str) : y column to be used   \n",
    "            - scoring(str) : sklearn cross-val scoring scheme\n",
    "            - n_iter_search : RandomizedSearchCV number of iteration\n",
    "    \"\"\"\n",
    "\n",
    "    model_fitted = random_search_cv(model, model_param,\n",
    "                                    params['scoring'],\n",
    "                                    params['n_iter_search'],\n",
    "                                    x_train, y_train,\n",
    "                                    params['verbosity'])\n",
    "\n",
    "    print(\n",
    "        f'Model: {model_fitted.best_estimator_}, {params[\"scoring\"]}: {model_fitted.best_score_}')\n",
    "\n",
    "    return model_fitted\n",
    "\n",
    "\n",
    "def validation_score(x_valid, y_valid, model_fitted):\n",
    "    \n",
    "    # Report default\n",
    "    y_predicted = model_fitted.predict(x_valid)\n",
    "    mae, mse, rmse, r2_square = evaluate(y_valid, y_predicted)\n",
    "    score = {'mae':mae, 'mse':mse, 'rmse':rmse, 'r2': r2_square}\n",
    "\n",
    "    return score\n",
    "\n",
    "def select_model(train_log_dict):\n",
    "    temp = []\n",
    "    for score in train_log_dict['model_score']:\n",
    "        temp.append(score['rmse'])\n",
    "    best_model = train_log_dict['model_fit'][temp.index(min(temp))]\n",
    "    best_parameter = train_log_dict['model_report'][temp.index(min(temp))]\n",
    "    best_report = train_log_dict['model_score'][temp.index(min(temp))]\n",
    "    \n",
    "    return best_model, best_parameter, best_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(params):\n",
    "    '''\n",
    "    Main function of modelling\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    params: .yaml file contain (dict) of general parameters for the read_data and model_lib function\n",
    "        - DUMP_TRAIN (str)  : location of preprocessed training data pickle\n",
    "        - Y_PATH_TRAIN (str): location of target column pickle for training data\n",
    "        - DUMP_VALID (str)  : location of preprocessed validation data pickle\n",
    "        - Y_PATH_VALID (str): location of target column  pickle validation data\n",
    "        - target(str) : y column to be used   \n",
    "        - scoring(str) : sklearn cross-val scoring scheme\n",
    "        - n_iter_search : RandomizedSearchCV number of iteration\n",
    "    '''\n",
    "\n",
    "    ridge = model_ridge\n",
    "    lasso = model_lasso\n",
    "    rf = model_rf\n",
    "    lsvr = model_svr\n",
    "    \n",
    "    # Make a dictionary \"train_log_dict\" to be saved later as pickle containing model information in training stage\n",
    "    train_log_dict = {'model': [ridge, lasso, rf, lsvr],\n",
    "                      'model_name': [],\n",
    "                      'model_fit': [],\n",
    "                      'model_report': [],\n",
    "                      'model_score': [],\n",
    "                      'fit_time': []}\n",
    "    \n",
    "    # Read data after preprocessing\n",
    "    x_train, y_train, x_valid, y_valid  = read_data(params)\n",
    "\n",
    "    # Iterate list model\n",
    "    for model in train_log_dict['model']:\n",
    "        # initiate the model\n",
    "        param_model, base_model = model()\n",
    "        # logging model name\n",
    "        train_log_dict['model_name'].append(base_model.__class__.__name__)\n",
    "        print(\n",
    "           f'Fitting {base_model.__class__.__name__}')\n",
    "\n",
    "        # Training\n",
    "        t0 = time.time()\n",
    "        \n",
    "        # Searching best parameter using Random Search CV\n",
    "        fitted_model, best_estimator = fit(\n",
    "            x_train, y_train, base_model, param_model, params)\n",
    "        elapsed_time = time.time() - t0\n",
    "        print(f'elapsed time: {elapsed_time} s \\n')\n",
    "        train_log_dict['fit_time'].append(elapsed_time)\n",
    "        train_log_dict['model_fit'].append(best_estimator.__class__.__name__)\n",
    "        \n",
    "        # Fitting model with best params to data training\n",
    "        best_estimator.fit(x_train, y_train)\n",
    "        train_log_dict['model_report'].append(best_estimator)\n",
    "\n",
    "        \n",
    "        # Validate model to validation data\n",
    "        score = validation_score( x_valid, y_valid, best_estimator)\n",
    "        train_log_dict['model_score'].append(score)\n",
    "\n",
    "    # Select which model in model list has best score evaluation (minimum rmse) in validation data\n",
    "    best_model, best_estimator, best_report = select_model(\n",
    "        train_log_dict)\n",
    "    print(\n",
    "        f\"Model: {best_model}, Score: {best_report}, Parameter: {best_estimator}\")\n",
    "    \n",
    "    # Dump model name\n",
    "    joblib.dump(best_model, f'output/model/model_name.pkl')\n",
    "    # Dump best model estimator with best param\n",
    "    joblib.dump(best_estimator, 'output/model/best_estimator.pkl')\n",
    "    # Dump training log\n",
    "    joblib.dump(train_log_dict, 'output/model/train_log.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Ridge\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "For multi-metric scoring, the parameter refit must be set to a scorer key or a callable to refit an estimator with the best parameter setting on the whole data and make the best_* attributes available for that metric. If this is not needed, refit should be set to False explicitly. True was passed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\yuha bach\\Downloads\\pmds v2\\general_main_v2.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/yuha%20bach/Downloads/pmds%20v2/general_main_v2.ipynb#ch0000017?line=0'>1</a>\u001b[0m main(params)\n",
      "\u001b[1;32mc:\\Users\\yuha bach\\Downloads\\pmds v2\\general_main_v2.ipynb Cell 17'\u001b[0m in \u001b[0;36mmain\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuha%20bach/Downloads/pmds%20v2/general_main_v2.ipynb#ch0000016?line=42'>43</a>\u001b[0m t0 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuha%20bach/Downloads/pmds%20v2/general_main_v2.ipynb#ch0000016?line=44'>45</a>\u001b[0m \u001b[39m# Searching best parameter using Random Search CV\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/yuha%20bach/Downloads/pmds%20v2/general_main_v2.ipynb#ch0000016?line=45'>46</a>\u001b[0m fitted_model, best_estimator \u001b[39m=\u001b[39m fit(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuha%20bach/Downloads/pmds%20v2/general_main_v2.ipynb#ch0000016?line=46'>47</a>\u001b[0m     x_train, y_train, base_model, param_model, params)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuha%20bach/Downloads/pmds%20v2/general_main_v2.ipynb#ch0000016?line=47'>48</a>\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m t0\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuha%20bach/Downloads/pmds%20v2/general_main_v2.ipynb#ch0000016?line=48'>49</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39melapsed time: \u001b[39m\u001b[39m{\u001b[39;00melapsed_time\u001b[39m}\u001b[39;00m\u001b[39m s \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\yuha bach\\Downloads\\pmds v2\\general_main_v2.ipynb Cell 15'\u001b[0m in \u001b[0;36mfit\u001b[1;34m(x_train, y_train, model, model_param, general_params)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yuha%20bach/Downloads/pmds%20v2/general_main_v2.ipynb#ch0000014?line=8'>9</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(x_train, y_train, model, model_param, general_params):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuha%20bach/Downloads/pmds%20v2/general_main_v2.ipynb#ch0000014?line=9'>10</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuha%20bach/Downloads/pmds%20v2/general_main_v2.ipynb#ch0000014?line=10'>11</a>\u001b[0m \u001b[39m    Fit model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuha%20bach/Downloads/pmds%20v2/general_main_v2.ipynb#ch0000014?line=11'>12</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuha%20bach/Downloads/pmds%20v2/general_main_v2.ipynb#ch0000014?line=18'>19</a>\u001b[0m \u001b[39m            - n_iter_search : RandomizedSearchCV number of iteration\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuha%20bach/Downloads/pmds%20v2/general_main_v2.ipynb#ch0000014?line=19'>20</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/yuha%20bach/Downloads/pmds%20v2/general_main_v2.ipynb#ch0000014?line=21'>22</a>\u001b[0m     model_fitted \u001b[39m=\u001b[39m random_search_cv(model, model_param,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuha%20bach/Downloads/pmds%20v2/general_main_v2.ipynb#ch0000014?line=22'>23</a>\u001b[0m                                     params[\u001b[39m'\u001b[39;49m\u001b[39mscoring\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuha%20bach/Downloads/pmds%20v2/general_main_v2.ipynb#ch0000014?line=23'>24</a>\u001b[0m                                     params[\u001b[39m'\u001b[39;49m\u001b[39mn_iter_search\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuha%20bach/Downloads/pmds%20v2/general_main_v2.ipynb#ch0000014?line=24'>25</a>\u001b[0m                                     x_train, y_train,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuha%20bach/Downloads/pmds%20v2/general_main_v2.ipynb#ch0000014?line=25'>26</a>\u001b[0m                                     params[\u001b[39m'\u001b[39;49m\u001b[39mverbosity\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuha%20bach/Downloads/pmds%20v2/general_main_v2.ipynb#ch0000014?line=27'>28</a>\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuha%20bach/Downloads/pmds%20v2/general_main_v2.ipynb#ch0000014?line=28'>29</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mModel: \u001b[39m\u001b[39m{\u001b[39;00mmodel_fitted\u001b[39m.\u001b[39mbest_estimator_\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mparams[\u001b[39m\"\u001b[39m\u001b[39mscoring\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mmodel_fitted\u001b[39m.\u001b[39mbest_score_\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuha%20bach/Downloads/pmds%20v2/general_main_v2.ipynb#ch0000014?line=30'>31</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model_fitted\n",
      "\u001b[1;32mc:\\Users\\yuha bach\\Downloads\\pmds v2\\general_main_v2.ipynb Cell 14'\u001b[0m in \u001b[0;36mrandom_search_cv\u001b[1;34m(model, param, scoring, n_iter, x, y, verbosity)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuha%20bach/Downloads/pmds%20v2/general_main_v2.ipynb#ch0000013?line=30'>31</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrandom_search_cv\u001b[39m(model, param, scoring, n_iter, x, y, verbosity\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuha%20bach/Downloads/pmds%20v2/general_main_v2.ipynb#ch0000013?line=31'>32</a>\u001b[0m     random_fit \u001b[39m=\u001b[39m RandomizedSearchCV(estimator\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuha%20bach/Downloads/pmds%20v2/general_main_v2.ipynb#ch0000013?line=32'>33</a>\u001b[0m                                     param_distributions\u001b[39m=\u001b[39mparam,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuha%20bach/Downloads/pmds%20v2/general_main_v2.ipynb#ch0000013?line=33'>34</a>\u001b[0m                                     scoring\u001b[39m=\u001b[39mscoring,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuha%20bach/Downloads/pmds%20v2/general_main_v2.ipynb#ch0000013?line=36'>37</a>\u001b[0m                                     random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuha%20bach/Downloads/pmds%20v2/general_main_v2.ipynb#ch0000013?line=37'>38</a>\u001b[0m                                     verbose\u001b[39m=\u001b[39mverbosity)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/yuha%20bach/Downloads/pmds%20v2/general_main_v2.ipynb#ch0000013?line=38'>39</a>\u001b[0m     random_fit\u001b[39m.\u001b[39;49mfit(x, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuha%20bach/Downloads/pmds%20v2/general_main_v2.ipynb#ch0000013?line=39'>40</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m random_fit\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\model_selection\\_search.py:796\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/yuha%20bach/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/sklearn/model_selection/_search.py?line=793'>794</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/yuha%20bach/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/sklearn/model_selection/_search.py?line=794'>795</a>\u001b[0m     scorers \u001b[39m=\u001b[39m _check_multimetric_scoring(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscoring)\n\u001b[1;32m--> <a href='file:///c%3A/Users/yuha%20bach/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/sklearn/model_selection/_search.py?line=795'>796</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_refit_for_multimetric(scorers)\n\u001b[0;32m    <a href='file:///c%3A/Users/yuha%20bach/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/sklearn/model_selection/_search.py?line=796'>797</a>\u001b[0m     refit_metric \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrefit\n\u001b[0;32m    <a href='file:///c%3A/Users/yuha%20bach/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/sklearn/model_selection/_search.py?line=798'>799</a>\u001b[0m X, y, groups \u001b[39m=\u001b[39m indexable(X, y, groups)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\model_selection\\_search.py:742\u001b[0m, in \u001b[0;36mBaseSearchCV._check_refit_for_multimetric\u001b[1;34m(self, scores)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/yuha%20bach/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/sklearn/model_selection/_search.py?line=734'>735</a>\u001b[0m valid_refit_dict \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrefit, \u001b[39mstr\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrefit \u001b[39min\u001b[39;00m scores\n\u001b[0;32m    <a href='file:///c%3A/Users/yuha%20bach/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/sklearn/model_selection/_search.py?line=736'>737</a>\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    <a href='file:///c%3A/Users/yuha%20bach/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/sklearn/model_selection/_search.py?line=737'>738</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrefit \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/yuha%20bach/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/sklearn/model_selection/_search.py?line=738'>739</a>\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m valid_refit_dict\n\u001b[0;32m    <a href='file:///c%3A/Users/yuha%20bach/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/sklearn/model_selection/_search.py?line=739'>740</a>\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrefit)\n\u001b[0;32m    <a href='file:///c%3A/Users/yuha%20bach/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/sklearn/model_selection/_search.py?line=740'>741</a>\u001b[0m ):\n\u001b[1;32m--> <a href='file:///c%3A/Users/yuha%20bach/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0/LocalCache/local-packages/Python38/site-packages/sklearn/model_selection/_search.py?line=741'>742</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(multimetric_refit_msg)\n",
      "\u001b[1;31mValueError\u001b[0m: For multi-metric scoring, the parameter refit must be set to a scorer key or a callable to refit an estimator with the best parameter setting on the whole data and make the best_* attributes available for that metric. If this is not needed, refit should be set to False explicitly. True was passed."
     ]
    }
   ],
   "source": [
    "main(params)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "49de8e361bcaa7b87b0d9a1948e17b94b1b6765468a847b75af4a4273d6c7723"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
