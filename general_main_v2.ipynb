{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path, path_ihsg, \n",
    "              save_file = True,\n",
    "              return_file = True,\n",
    "              set_index = None):\n",
    "\n",
    "\n",
    "    emiten = pd.read_csv(path, index_col = set_index)\n",
    "    ihsg = pd.read_csv(path_ihsg, index_col = set_index)\n",
    "    merged = pd.merge(emiten, ihsg, how='left', on='Date')\n",
    "    merged['Close+1'] = merged['Close_x'].shift(-1)\n",
    "\n",
    "    if save_file:\n",
    "        joblib.dump(merged, \"output/merged.pkl\")\n",
    "    \n",
    "    if return_file:\n",
    "        return merged\n",
    "\n",
    "\n",
    "\n",
    "def split_input_output(dataset,\n",
    "                       target_column,\n",
    "                       save_file = True,\n",
    "                       return_file = True):\n",
    "    \n",
    "    output_df = dataset[target_column].reset_index(drop=True)\n",
    "    input_df = dataset.drop([target_column],\n",
    "                            axis = 1)\n",
    "    \n",
    "    if save_file:\n",
    "        joblib.dump(output_df, \"output/output_df.pkl\")\n",
    "        joblib.dump(input_df, \"output/input_df.pkl\")\n",
    "    \n",
    "    if return_file:\n",
    "        return output_df, input_df\n",
    "\n",
    "def x_split(input_df, return_file=True, save_file=True):\n",
    "    X_train = input_df[:int(input_df.shape[0]*0.6)]\n",
    "    test_val = input_df[int(input_df.shape[0]*0.6):]\n",
    "    X_valid = test_val[:int(test_val.shape[0]*0.5)]\n",
    "    X_test = test_val[int(test_val.shape[0]*0.5):]\n",
    "\n",
    "    if save_file:\n",
    "        joblib.dump(X_train, \"output/X_train.pkl\")\n",
    "        joblib.dump(X_valid, \"output/X_valid.pkl\")\n",
    "        joblib.dump(X_test, \"output/X_test.pkl\")\n",
    "\n",
    "    if return_file:\n",
    "        return X_train, X_valid, X_test\n",
    "        \n",
    "def y_split(output_df, return_file=True, save_file=True):\n",
    "    y_train = output_df[:int(output_df.shape[0]*0.6)]\n",
    "    y_test_val = output_df[int(output_df.shape[0]*0.6):]\n",
    "    y_valid = y_test_val[:int(y_test_val.shape[0]*0.5)]\n",
    "    y_test = y_test_val[int(y_test_val.shape[0]*0.5):]\n",
    "    \n",
    "    if save_file:\n",
    "        joblib.dump(y_train, \"output/y_train.pkl\")\n",
    "        joblib.dump(y_valid, \"output/y_valid.pkl\")\n",
    "        joblib.dump(y_test, \"output/y_test.pkl\")\n",
    "\n",
    "    if return_file:\n",
    "        return y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/AMRT.csv\"\n",
    "DATA_PATH_IHSG = \"data/ihsg.csv\"\n",
    "TARGET_COLUMN = \"Close+1\"\n",
    "INDEX_COLUMN = \"Date\"\n",
    "\n",
    "data_house = read_data(DATA_PATH, DATA_PATH_IHSG,\n",
    "                       set_index = INDEX_COLUMN)\n",
    "output_df, input_df = split_input_output(\n",
    "                            data_house,\n",
    "                            TARGET_COLUMN)\n",
    "\n",
    "X_train, X_valid, X_test = x_split(input_df)\n",
    "y_train, y_valid, y_test = y_split(output_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_emiten(proceed):\n",
    "    proceed = proceed.drop(['Open_x', 'Open_y', 'High_x', 'High_y', 'Low_x', 'Low_y', 'Adj Close_x', 'Adj Close_y'], axis = 1)\n",
    "    proceed.rename(columns = {'Close_x':'Close', 'Volume_x':'Volume', 'Close_y':'Close_ihsg', 'Volume_y':'Volume_ihsg'}, inplace = True)\n",
    "    proceed = proceed.replace(to_replace=0, method='bfill')\n",
    "    proceed = proceed.fillna(method='bfill')\n",
    "    return proceed\n",
    "\n",
    "def process_y(y_data):\n",
    "    y_data = y_data.replace(to_replace=0, method='bfill')\n",
    "    y_data = y_data.fillna(method='bfill')\n",
    "    return y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_data(save_file=True, return_file=True):\n",
    "    X_train = process_emiten(joblib.load(\"output/X_train.pkl\"))\n",
    "    X_valid = process_emiten(joblib.load(\"output/X_valid.pkl\"))\n",
    "    X_test = process_emiten(joblib.load(\"output/X_test.pkl\"))\n",
    "    y_train = process_y(joblib.load(\"output/y_train.pkl\"))\n",
    "    y_valid = process_y(joblib.load(\"output/y_valid.pkl\"))\n",
    "    y_test = process_y(joblib.load(\"output/y_test.pkl\"))\n",
    "    \n",
    "    if save_file:\n",
    "        joblib.dump(X_train, \"output/X_train_proceed.pkl\")\n",
    "        joblib.dump(X_valid, \"output/X_valid_proceed.pkl\")\n",
    "        joblib.dump(X_test, \"output/X_test_proceed.pkl\")\n",
    "        joblib.dump(y_train, \"output/y_train_final.pkl\")\n",
    "        joblib.dump(y_valid, \"output/y_valid_final.pkl\")\n",
    "        joblib.dump(y_test, \"output/y_test_final.pkl\")\n",
    "    if return_file:\n",
    "        X_train, X_valid, X_test, y_train, y_valid, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sma(xdata):\n",
    "    periode = [5,20,60,120]\n",
    "    alpha = [0.1, 0.3]\n",
    "    for i in periode:\n",
    "        for k in alpha:\n",
    "            xdata[\"SMA_\", i] = xdata.Close.rolling(i, min_periods=1).mean()\n",
    "            xdata[\"dis_sma\", i] = xdata[\"Close\"] - xdata[\"SMA_\", i]\n",
    "            xdata[\"em_\", k] = xdata.Close.ewm(alpha=k, adjust=False).mean()\n",
    "    xdata.rename(columns = {('SMA_', 5):'SMA_5',\n",
    "                        ('SMA_', 20):'SMA_20',\n",
    "                        ('SMA_', 60): 'SMA_60', \n",
    "                        ('SMA_', 120): 'SMA_120',\n",
    "                        ('em_', 0.1): 'em_0.1',\n",
    "                        ('em_', 0.3): 'em_0.3',\n",
    "                        ('dis_sma', 5): 'dis_sam_5',\n",
    "                        ('dis_sma', 20): 'dis_sam_20',\n",
    "                        ('dis_sma', 60): 'dis_sam_60',\n",
    "                        ('dis_sma', 120): 'dis_sam_120'}, inplace = True)\n",
    "    return xdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(x_all):\n",
    "    index = x_all.index\n",
    "    cols = x_all.columns\n",
    "    normalizer = StandardScaler()\n",
    "    normalizer.fit(x_all)        \n",
    "    normalized = normalizer.transform(x_all)\n",
    "    normalized = pd.DataFrame(normalized)\n",
    "    normalized.index = index\n",
    "    normalized.columns = cols\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_sma(save_file=True, return_file=True):\n",
    "    X_train = normalization(make_sma(joblib.load(\"output/X_train_proceed.pkl\")))\n",
    "    X_valid = normalization(make_sma(joblib.load(\"output/X_valid_proceed.pkl\")))\n",
    "    X_test = normalization(make_sma(joblib.load(\"output/X_test_proceed.pkl\")))\n",
    "    \n",
    "    if save_file:\n",
    "        joblib.dump(X_train, \"output/X_train_final.pkl\")\n",
    "        joblib.dump(X_valid, \"output/X_valid_final.pkl\")\n",
    "        joblib.dump(X_test, \"output/X_test_final.pkl\")\n",
    "    if return_file:\n",
    "        X_train, X_valid, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import random\n",
    "import yaml\n",
    "import time\n",
    "\n",
    "ts_cv = TimeSeriesSplit(\n",
    "    n_splits=5,\n",
    "    max_train_size=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"params.yaml\", \"r\")\n",
    "params = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(params):\n",
    "    x_train = joblib.load(params['DUMP_TRAIN'])\n",
    "    y_train = joblib.load(params['Y_PATH_TRAIN'])\n",
    "    x_valid = joblib.load(params['DUMP_VALID'])\n",
    "    y_valid = joblib.load(params['Y_PATH_VALID'])\n",
    "\n",
    "    return x_train, y_train, x_valid, y_valid\n",
    "\n",
    "def model_ridge():\n",
    "    param_dist = {'alpha': [0.1, 0.25, 0.5, 0.75]}\n",
    "    base_model = Ridge(random_state=42)\n",
    "    return param_dist, base_model\n",
    "\n",
    "def model_lasso():\n",
    "    param_dist = {'alpha': np.random.uniform(0.01,3,1000)}\n",
    "    base_model = Lasso(random_state=42, selection='random')\n",
    "    return param_dist, base_model\n",
    "\n",
    "\n",
    "def model_rf():\n",
    "    param_dist = {\"n_estimators\": [100, 250, 500, 1000]}\n",
    "    base_model = RandomForestRegressor(random_state=0, n_jobs=-1)\n",
    "    return param_dist, base_model\n",
    "\n",
    "\n",
    "def model_svr():\n",
    "    param_dist = {'C': [0.25, 0.5, 1, 1.25]}\n",
    "    base_model = LinearSVR(dual=False, max_iter=10000)\n",
    "    return param_dist, base_model\n",
    "\n",
    "def random_search_cv(model, param, scoring, n_iter, x, y, verbosity=0):\n",
    "    random_fit = RandomizedSearchCV(estimator=model,\n",
    "                                    param_distributions=param,\n",
    "                                    scoring=scoring,\n",
    "                                    n_iter=n_iter,\n",
    "                                    cv=ts_cv,\n",
    "                                    random_state=0,\n",
    "                                    verbose=verbosity,\n",
    "                                    refit=\"neg_root_mean_squared_error\")\n",
    "    random_fit.fit(x, y)\n",
    "    return random_fit\n",
    "\n",
    "def evaluate(true, predicted):\n",
    "    mae = metrics.mean_absolute_error(true, predicted)\n",
    "    mse = metrics.mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n",
    "    r2_square = metrics.r2_score(true, predicted)\n",
    "    return mae, mse, rmse, r2_square\n",
    "\n",
    "\n",
    "def fit(x_train, y_train, model, model_param, params):\n",
    "    \"\"\"\n",
    "    Fit model\n",
    "\n",
    "    Args:\n",
    "        - model(callable): Sklearn / imblearn model\n",
    "        - model_param(dict): sklearn's RandomizedSearchCV param_distribution\n",
    "        - general_params(dict): general parameters for the function\n",
    "            - target(str) : y column to be used   \n",
    "            - scoring(str) : sklearn cross-val scoring scheme\n",
    "            - n_iter_search : RandomizedSearchCV number of iteration\n",
    "    \"\"\"\n",
    "    \n",
    "    model_fitted = random_search_cv(model, model_param,\n",
    "                                    params['scoring'],\n",
    "                                    params['n_iter_search'],\n",
    "                                    x_train, y_train,\n",
    "                                    params['verbosity'])\n",
    "\n",
    "    print(\n",
    "        f'Model: {model_fitted.best_estimator_}, {params[\"scoring\"]}: {model_fitted.best_score_}')\n",
    "\n",
    "    return  model_fitted.best_score_, model_fitted.best_estimator_\n",
    "\n",
    "\n",
    "def validation_score(x_valid, y_valid, model_fitted):\n",
    "    \n",
    "    # Report default\n",
    "    y_predicted = model_fitted.predict(x_valid)\n",
    "    mae, mse, rmse, r2_square = evaluate(y_valid, y_predicted)\n",
    "    score = {'mae':mae, 'mse':mse, 'rmse':rmse, 'r2': r2_square}\n",
    "\n",
    "    return score\n",
    "\n",
    "def select_model(train_log_dict):\n",
    "    temp = []\n",
    "    for score in train_log_dict['model_score']:\n",
    "        temp.append(score['rmse'])\n",
    "    best_model = train_log_dict['model_fit'][temp.index(min(temp))]\n",
    "    best_parameter = train_log_dict['model_report'][temp.index(min(temp))]\n",
    "    best_report = train_log_dict['model_score'][temp.index(min(temp))]\n",
    "    \n",
    "    return best_model, best_parameter, best_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(params):\n",
    "    '''\n",
    "    Main function of modelling\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    params: .yaml file contain (dict) of general parameters for the read_data and model_lib function\n",
    "        - DUMP_TRAIN (str)  : location of preprocessed training data pickle\n",
    "        - Y_PATH_TRAIN (str): location of target column pickle for training data\n",
    "        - DUMP_VALID (str)  : location of preprocessed validation data pickle\n",
    "        - Y_PATH_VALID (str): location of target column  pickle validation data\n",
    "        - target(str) : y column to be used   \n",
    "        - scoring(str) : sklearn cross-val scoring scheme\n",
    "        - n_iter_search : RandomizedSearchCV number of iteration\n",
    "    '''\n",
    "\n",
    "    ridge = model_ridge\n",
    "    lasso = model_lasso\n",
    "    rf = model_rf\n",
    "    lsvr = model_svr\n",
    "    \n",
    "    # Make a dictionary \"train_log_dict\" to be saved later as pickle containing model information in training stage\n",
    "    train_log_dict = {'model': [ridge, lasso, rf, lsvr],\n",
    "                      'model_name': [],\n",
    "                      'model_fit': [],\n",
    "                      'model_report': [],\n",
    "                      'model_score': [],\n",
    "                      'fit_time': []}\n",
    "    \n",
    "    # Read data after preprocessing\n",
    "    x_train, y_train, x_valid, y_valid  = read_data(params)\n",
    "    # Iterate list model\n",
    "    for model in train_log_dict['model']:\n",
    "        # initiate the model\n",
    "        param_model, base_model = model()\n",
    "        # logging model name\n",
    "        train_log_dict['model_name'].append(base_model.__class__.__name__)\n",
    "        print(\n",
    "           f'Fitting {base_model.__class__.__name__}')\n",
    "\n",
    "        # Training\n",
    "        t0 = time.time()\n",
    "        \n",
    "        # Searching best parameter using Random Search CV\n",
    "        fitted_model, best_estimator = fit(\n",
    "            x_train, y_train, base_model, param_model, params)\n",
    "        elapsed_time = time.time() - t0\n",
    "        print(f'elapsed time: {elapsed_time} s \\n')\n",
    "        train_log_dict['fit_time'].append(elapsed_time)\n",
    "        train_log_dict['model_fit'].append(best_estimator.__class__.__name__)\n",
    "        \n",
    "        # Fitting model with best params to data training\n",
    "        best_estimator.fit(x_train, y_train)\n",
    "        train_log_dict['model_report'].append(best_estimator)\n",
    "\n",
    "        \n",
    "        # Validate model to validation data\n",
    "        score = validation_score( x_valid, y_valid, best_estimator)\n",
    "        train_log_dict['model_score'].append(score)\n",
    "\n",
    "    # Select which model in model list has best score evaluation (minimum rmse) in validation data\n",
    "    best_model, best_estimator, best_report = select_model(\n",
    "        train_log_dict)\n",
    "    print(\n",
    "        f\"Model: {best_model}, Score: {best_report}, Parameter: {best_estimator}\")\n",
    "    \n",
    "    # Dump model name\n",
    "    joblib.dump(best_model, f'output/model/model_name.pkl')\n",
    "    # Dump best model estimator with best param\n",
    "    joblib.dump(best_estimator, 'output/model/best_estimator.pkl')\n",
    "    # Dump training log\n",
    "    joblib.dump(train_log_dict, 'output/model/train_log.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "49de8e361bcaa7b87b0d9a1948e17b94b1b6765468a847b75af4a4273d6c7723"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
