{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import random\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import time\n",
    "import joblib\n",
    "\n",
    "ts_cv = TimeSeriesSplit(\n",
    "    n_splits=5,\n",
    "    max_train_size=None,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(params):\n",
    "    '''\n",
    "    Main function of modelling\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    params: .yaml file contain (dict) of general parameters for the read_data and model_lib function\n",
    "        - DUMP_TRAIN (str)  : location of preprocessed training data pickle\n",
    "        - Y_PATH_TRAIN (str): location of target column pickle for training data\n",
    "        - DUMP_VALID (str)  : location of preprocessed validation data pickle\n",
    "        - Y_PATH_VALID (str): location of target column  pickle validation data\n",
    "        - target(str) : y column to be used   \n",
    "        - scoring(str) : sklearn cross-val scoring scheme\n",
    "        - n_iter_search : RandomizedSearchCV number of iteration\n",
    "    '''\n",
    "\n",
    "    lasso = model_search.model_lasso\n",
    "    rf = model_search.model_rf\n",
    "    lsvr = model_search.model_svr\n",
    "    \n",
    "    # Make a dictionary \"train_log_dict\" to be saved later as pickle containing model information in training stage\n",
    "    train_log_dict = {'model': [lasso, rf, lsvr],\n",
    "                      'model_name': [],\n",
    "                      'model_fit': [],\n",
    "                      'model_report': [],\n",
    "                      'model_score': [],\n",
    "                      'fit_time': []}\n",
    "    \n",
    "    # Read data after preprocessing\n",
    "    x_train, y_train, x_valid, y_valid  = read_data(params)\n",
    "\n",
    "    # Iterate list model\n",
    "    for model in train_log_dict['model']:\n",
    "        # initiate the model\n",
    "        param_model, base_model = model()\n",
    "        # logging model name\n",
    "        train_log_dict['model_name'].append(base_model.__class__.__name__)\n",
    "        print(\n",
    "           f'Fitting {base_model.__class__.__name__}')\n",
    "\n",
    "        # Training\n",
    "        t0 = time.time()\n",
    "        \n",
    "        # Searching best parameter using Random Search CV\n",
    "        fitted_model,best_estimator = model_search.fit(\n",
    "            x_train, y_train, base_model, param_model, params)\n",
    "        elapsed_time = time.time() - t0\n",
    "        print(f'elapsed time: {elapsed_time} s \\n')\n",
    "        train_log_dict['fit_time'].append(elapsed_time)\n",
    "        train_log_dict['model_fit'].append(best_estimator.__class__.__name__)\n",
    "        \n",
    "        # Fitting model with best params to data training\n",
    "        best_estimator.fit(x_train, y_train)\n",
    "        train_log_dict['model_report'].append(best_estimator)\n",
    "\n",
    "        \n",
    "        # Validate model to validation data\n",
    "        score = model_search.validation_score( x_valid, y_valid, best_estimator)\n",
    "        train_log_dict['model_score'].append(score)\n",
    "\n",
    "    # Select which model in model list has best score evaluation (minimum rmse) in validation data\n",
    "    best_model, best_estimator, best_report = model_search.select_model(\n",
    "        train_log_dict)\n",
    "    print(\n",
    "        f\"Model: {best_model}, Score: {best_report}, Parameter: {best_estimator}\")\n",
    "    \n",
    "    # Dump model name\n",
    "    joblib.dump(best_model, f'output/model/train/model_name_v1.1.pkl')\n",
    "    # Dump best model estimator with best param\n",
    "    joblib.dump(best_estimator, 'output/model/train/best_estimator_v1.1.pkl')\n",
    "    # Dump training log\n",
    "    joblib.dump(train_log_dict, 'output/model/train/train_log_v1.1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "49de8e361bcaa7b87b0d9a1948e17b94b1b6765468a847b75af4a4273d6c7723"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
