{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path, path_ihsg, \n",
    "              save_file = True,\n",
    "              return_file = True,\n",
    "              set_index = None):\n",
    "\n",
    "\n",
    "    emiten = pd.read_csv(path, index_col = set_index)\n",
    "    ihsg = pd.read_csv(path_ihsg, index_col = set_index)\n",
    "    merged = pd.merge(emiten, ihsg, how='left', on='Date')\n",
    "    merged['Close+1'] = merged['Close_x'].shift(-1)\n",
    "\n",
    "    if save_file:\n",
    "        joblib.dump(merged, \"output/merged.pkl\")\n",
    "    \n",
    "    if return_file:\n",
    "        return merged\n",
    "\n",
    "\n",
    "\n",
    "def split_input_output(dataset,\n",
    "                       target_column,\n",
    "                       save_file = True,\n",
    "                       return_file = True):\n",
    "    \n",
    "    output_df = dataset[target_column]\n",
    "    input_df = dataset.drop([target_column],\n",
    "                            axis = 1)\n",
    "    \n",
    "    if save_file:\n",
    "        joblib.dump(output_df, \"output/output_df.pkl\")\n",
    "        joblib.dump(input_df, \"output/input_df.pkl\")\n",
    "    \n",
    "    if return_file:\n",
    "        return output_df, input_df\n",
    "\n",
    "def x_split(input_df, return_file=True, save_file=True):\n",
    "    X_train = input_df[:int(input_df.shape[0]*0.6)]\n",
    "    test_val = input_df[int(input_df.shape[0]*0.6):]\n",
    "    X_valid = test_val[:int(test_val.shape[0]*0.5)]\n",
    "    X_test = test_val[int(test_val.shape[0]*0.5):]\n",
    "\n",
    "    if save_file:\n",
    "        joblib.dump(X_train, \"output/X_train.pkl\")\n",
    "        joblib.dump(X_valid, \"output/X_valid.pkl\")\n",
    "        joblib.dump(X_test, \"output/X_test.pkl\")\n",
    "\n",
    "    if return_file:\n",
    "        return X_train, X_valid, X_test\n",
    "        \n",
    "def y_split(output_df, return_file=True, save_file=True):\n",
    "    y_train = output_df[:int(output_df.shape[0]*0.6)]\n",
    "    y_test_val = output_df[int(output_df.shape[0]*0.6):]\n",
    "    y_valid = y_test_val[:int(y_test_val.shape[0]*0.5)]\n",
    "    y_test = y_test_val[int(y_test_val.shape[0]*0.5):]\n",
    "    \n",
    "    if save_file:\n",
    "        joblib.dump(y_train, \"output/y_train.pkl\")\n",
    "        joblib.dump(y_valid, \"output/y_valid.pkl\")\n",
    "        joblib.dump(y_test, \"output/y_test.pkl\")\n",
    "\n",
    "    if return_file:\n",
    "        return y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/AMRT.csv\"\n",
    "DATA_PATH_IHSG = \"data/ihsg.csv\"\n",
    "TARGET_COLUMN = \"Close+1\"\n",
    "INDEX_COLUMN = \"Date\"\n",
    "\n",
    "data_house = read_data(DATA_PATH, DATA_PATH_IHSG,\n",
    "                       set_index = INDEX_COLUMN)\n",
    "output_df, input_df = split_input_output(\n",
    "                            data_house,\n",
    "                            TARGET_COLUMN)\n",
    "\n",
    "X_train, X_val, X_test = x_split(input_df)\n",
    "y_train, y_val, y_test = y_split(output_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_emiten(proceed):\n",
    "    proceed = proceed.drop(['Open_x', 'Open_y', 'High_x', 'High_y', 'Low_x', 'Low_y', 'Adj Close_x', 'Adj Close_y'], axis = 1)\n",
    "    proceed.rename(columns = {'Close_x':'Close', 'Volume_x':'Volume', 'Close_y':'Close_ihsg', 'Volume_y':'Volume_ihsg'}, inplace = True)\n",
    "    proceed.dropna(inplace=True)\n",
    "    proceed.drop(proceed.loc[proceed[\"Volume\"]==0].index, inplace=True)\n",
    "    proceed.drop(proceed.loc[proceed[\"Volume_ihsg\"]==0].index, inplace=True)\n",
    "    return proceed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_data(save_file=True, return_file=True):\n",
    "    X_train = process_emiten(joblib.load(\"output/X_train.pkl\"))\n",
    "    X_valid = process_emiten(joblib.load(\"output/X_valid.pkl\"))\n",
    "    X_test = process_emiten(joblib.load(\"output/X_test.pkl\"))\n",
    "    \n",
    "    if save_file:\n",
    "        joblib.dump(X_train, \"output/X_train_proceed.pkl\")\n",
    "        joblib.dump(X_valid, \"output/X_valid_proceed.pkl\")\n",
    "        joblib.dump(X_test, \"output/X_test_proceed.pkl\")\n",
    "    if return_file:\n",
    "        X_train, X_valid, X_test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sma(xdata, save_file=True, return_file=True):\n",
    "    periode = [5,20,60,120]\n",
    "    alpha = [0.1, 0.3]\n",
    "    for i in periode:\n",
    "        for k in alpha:\n",
    "            xdata[\"SMA_\", i] = xdata.Close.rolling(i, min_periods=1).mean()\n",
    "            xdata[\"dis_sma\", i] = xdata[\"Close\"] - xdata[\"SMA_\", i]\n",
    "            xdata[\"em_\", k] = xdata.Close.ewm(alpha=k, adjust=False).mean()\n",
    "    xdata.rename(columns = {('SMA_', 5):'SMA_5',\n",
    "                        ('SMA_', 20):'SMA_20',\n",
    "                        ('SMA_', 60): 'SMA_60', \n",
    "                        ('SMA_', 120): 'SMA_120',\n",
    "                        ('em_', 0.1): 'em_0.1',\n",
    "                        ('em_', 0.3): 'em_0.3',\n",
    "                        ('dis_sma', 5): 'dis_sam_5',\n",
    "                        ('dis_sma', 20): 'dis_sam_20',\n",
    "                        ('dis_sma', 60): 'dis_sam_60',\n",
    "                        ('dis_sma', 120): 'dis_sam_120'}, inplace = True)\n",
    "    return xdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_sma(save_file=True, return_file=True):\n",
    "    X_train = make_sma(joblib.load(\"output/X_train_proceed.pkl\"))\n",
    "    X_valid = make_sma(joblib.load(\"output/X_valid_proceed.pkl\"))\n",
    "    X_test = make_sma(joblib.load(\"output/X_test_proceed.pkl\"))\n",
    "    \n",
    "    if save_file:\n",
    "        joblib.dump(X_train, \"output/X_train_final.pkl\")\n",
    "        joblib.dump(X_valid, \"output/X_valid_final.pkl\")\n",
    "        joblib.dump(X_test, \"output/X_test_final.pkl\")\n",
    "    if return_file:\n",
    "        X_train, X_valid, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import metrics\n",
    "import random\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"params.yaml\", \"r\")\n",
    "params = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(params):\n",
    "    x_train = joblib.load(params['DUMP_TRAIN'])\n",
    "    y_train = joblib.load(params['Y_PATH_TRAIN'])\n",
    "    x_valid = joblib.load(params['DUMP_VALID'])\n",
    "    y_valid = joblib.load(params['Y_PATH_VALID'])\n",
    "\n",
    "    return x_train, y_train, x_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = read_data(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "409f3fa671dd4c6947dbff9f29c9a7c34dc2c0b74800bf9cc8e3282d295632e5"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
