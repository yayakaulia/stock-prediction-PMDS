{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path, path_ihsg, \n",
    "              save_file = True,\n",
    "              return_file = True,\n",
    "              set_index = None):\n",
    "\n",
    "\n",
    "    emiten = pd.read_csv(path, index_col = set_index)\n",
    "    ihsg = pd.read_csv(path_ihsg, index_col = set_index)\n",
    "    merged = pd.merge(emiten, ihsg, how='left', on='Date')\n",
    "    merged['Close+1'] = merged['Close_x'].shift(-1)\n",
    "\n",
    "    if save_file:\n",
    "        joblib.dump(merged, \"output/merged.pkl\")\n",
    "    \n",
    "    if return_file:\n",
    "        return merged\n",
    "\n",
    "\n",
    "\n",
    "def split_input_output(dataset,\n",
    "                       target_column,\n",
    "                       save_file = True,\n",
    "                       return_file = True):\n",
    "    \n",
    "    output_df = dataset[target_column]\n",
    "    input_df = dataset.drop([target_column],\n",
    "                            axis = 1)\n",
    "    \n",
    "    if save_file:\n",
    "        joblib.dump(output_df, \"output/output_df.pkl\")\n",
    "        joblib.dump(input_df, \"output/input_df.pkl\")\n",
    "    \n",
    "    if return_file:\n",
    "        return output_df, input_df\n",
    "\n",
    "def x_split(input_df, return_file=True, save_file=True):\n",
    "    X_train = input_df[:int(input_df.shape[0]*0.6)]\n",
    "    test_val = input_df[int(input_df.shape[0]*0.6):]\n",
    "    X_val = test_val[:int(test_val.shape[0]*0.5)]\n",
    "    X_test = test_val[int(test_val.shape[0]*0.5):]\n",
    "\n",
    "    if save_file:\n",
    "        joblib.dump(X_train, \"output/X_train.pkl\")\n",
    "        joblib.dump(X_val, \"output/X_valid.pkl\")\n",
    "        joblib.dump(X_test, \"output/X_test.pkl\")\n",
    "\n",
    "    if return_file:\n",
    "        return X_train, X_val, X_test\n",
    "        \n",
    "def y_split(output_df, return_file=True, save_file=True):\n",
    "    y_train = output_df[:int(output_df.shape[0]*0.6)]\n",
    "    y_test_val = output_df[int(output_df.shape[0]*0.6):]\n",
    "    y_val = y_test_val[:int(y_test_val.shape[0]*0.5)]\n",
    "    y_test = y_test_val[int(y_test_val.shape[0]*0.5):]\n",
    "    \n",
    "    if save_file:\n",
    "        joblib.dump(y_train, \"output/y_train.pkl\")\n",
    "        joblib.dump(y_val, \"output/y_valid.pkl\")\n",
    "        joblib.dump(y_test, \"output/y_test.pkl\")\n",
    "\n",
    "    if return_file:\n",
    "        return y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/AMRT.csv\"\n",
    "DATA_PATH_IHSG = \"data/ihsg.csv\"\n",
    "TARGET_COLUMN = \"Close+1\"\n",
    "INDEX_COLUMN = \"Date\"\n",
    "\n",
    "data_house = read_data(DATA_PATH, DATA_PATH_IHSG,\n",
    "                       set_index = INDEX_COLUMN)\n",
    "output_df, input_df = split_input_output(\n",
    "                            data_house,\n",
    "                            TARGET_COLUMN)\n",
    "\n",
    "X_train, X_val, X_test = x_split(input_df)\n",
    "y_train, y_val, y_test = y_split(output_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_emiten(proceed, save_file=True, return_file=True):\n",
    "        proceed = proceed.drop(['Open_x', 'Open_y', 'High_x', 'High_y', 'Low_x', 'Low_y', 'Adj Close_x', 'Adj Close_y'], axis = 1)\n",
    "        proceed.rename(columns = {'Close_x':'Close', 'Volume_x':'Volume', 'Close_y':'Close_ihsg', 'Volume_y':'Volume_ihsg'}, inplace = True)\n",
    "        proceed.dropna(inplace=True)\n",
    "        proceed.drop(proceed.loc[proceed[\"Volume\"]==0].index, inplace=True)\n",
    "        proceed.drop(proceed.loc[proceed[\"Volume_ihsg\"]==0].index, inplace=True)\n",
    "        \n",
    "        if save_file:\n",
    "            joblib.dump(proceed, \"output/proceed.pkl\")\n",
    "        \n",
    "        if return_file:\n",
    "            return proceed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMA(feature_sma):\n",
    "    feature_smas = []\n",
    "    periode = [5,20,60,120]\n",
    "    for i in periode:\n",
    "        feature_sma[\"SMA_\", i] = feature_sma.Close.rolling(i, min_periods=1).mean()\n",
    "    return feature_sma.append(feature_smas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EMA(feature_ema):\n",
    "    feature_emas = []\n",
    "    periodes = [0.1, 0.3]\n",
    "    for i in periodes:\n",
    "        feature_ema[\"em_\", i] = feature_ema.Close.ewm(alpha=i, adjust=False).mean()\n",
    "    return feature_ema.append(feature_emas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dis_sma(feature_dis):\n",
    "    feature_dis_get = []\n",
    "    periode = [5,20,60,120]\n",
    "    for i in periode:\n",
    "        feature_dis[\"dis_sma\", i] = feature_dis[\"Close\"] - SMA(feature_dis)[\"SMA_\", i]\n",
    "    return feature_dis.append(feature_dis_get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import metrics\n",
    "import random\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"params.yaml\", \"r\")\n",
    "params = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(params):\n",
    "    x_train = joblib.load(params['DUMP_TRAIN'])\n",
    "    y_train = joblib.load(params['Y_PATH_TRAIN'])\n",
    "    x_valid = joblib.load(params['DUMP_VALID'])\n",
    "    y_valid = joblib.load(params['Y_PATH_VALID'])\n",
    "\n",
    "    return x_train, y_train, x_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = read_data(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "409f3fa671dd4c6947dbff9f29c9a7c34dc2c0b74800bf9cc8e3282d295632e5"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
